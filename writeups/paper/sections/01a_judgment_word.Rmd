

# Study 1: Measuring gender bias: behavioral evidence

## Study 1a: Gender bias in words

As a first step we asked adult English speakers to rate the genderedness of words in these books using a 5-point scale from masculine to feminine [@scott2019glasgow]\footnote{We operationalize gender as a continuum ranging from masculine to feminine throughout, and use the terms "masculine" and "feminine" interchangebly with "male" and "female". This approach ignores many aspects of gender that not critical to the present research question.} This procedure yields systematic data with good face validity: words such as "axe" and "engine" as masculine, "cuddle" and "pink" are rated as feminine,"exactly" and "nose" as neutral.

### Method

```{r}
RATING_DEMO_PATH <- here("data/processed/words/gender_ratings_demographics.csv")
EXCLUDED_TURKERS_PATH <-  here("data/processed/words/n_participants_attention_excluded.csv")

num_excluded_attention_check <- read_csv(EXCLUDED_TURKERS_PATH) %>%
  pull(num_excluded_attention_check)

num_excluded_midpoint <- read_csv(EXCLUDED_TURKERS_PATH) %>%
  pull(num_excluded_midpoint)

rating_demos <- read_csv(RATING_DEMO_PATH)

non_native_participants <- rating_demos %>%
  filter(question_name == "native_english" | question_name == "native") %>%
  filter(response_str == 0) %>%
  pull(subj_id)

rating_demos_ex <- rating_demos %>%
  filter(!(subj_id %in% non_native_participants))

gender_data <- rating_demos_ex %>%
  filter(question_name == "gender") %>%
  count(response_str)

age_mean <- rating_demos_ex %>%
  filter(question_name == "age")  %>%
  mutate(response_str = as.numeric(response_str)) %>%
  summarize(
    sd_age = sd(response_str, na.rm = T),
    mean_age = mean(response_str, na.rm = T)) %>%
  mutate_if(is.numeric, round, 1)

edu_data <- rating_demos_ex %>%
  filter(question_name == "education") %>%
  mutate(response_str = as.factor(response_str)) %>%
  rename(edu = response_str) %>%
  select(-question_name)
``` 


Participants (_N_ = `r length(unique(rating_demos_ex$subj_id)) + length(non_native_participants) + num_excluded_attention_check + num_excluded_midpoint`) were recruited on Amazon Mechanical Turk. Participants who answered any of 6 performance integrity check items incorrectly (e.g., “The word red has two letters”) were excluded (_N_ = `r num_excluded_attention_check`). One participant who responded with the midpoint on almost all items and 6 non-native English speakers were also excluded. The final sample included `r length(unique(rating_demos_ex$subj_id))` participants (`r filter(gender_data, response_str == "male")$n`  who identified as male, `r filter(gender_data, response_str == "female")$n` female, `r filter(gender_data, response_str == "other")$n` other), with a mean age of `r printnum(pull(age_mean,mean_age))` years (_SD_ = `r printnum(pull(age_mean,sd_age))`).\footnote{All data and code available in a public repository: \url{https://github.com/mllewis/WCBC_GENDER}}

```{r stimuli}
RATING_RATINGS_PATH <- here("data/processed/words/gender_ratings.csv")
ratings <- read_csv(RATING_RATINGS_PATH, col_names = TRUE, 
                    cols(subj_id = "c", word = "c", rating = "n")) %>%
  filter(!(subj_id %in% non_native_participants))


N_ratings_per_subject <- ratings %>%
  count(subj_id) %>%
  summarize(min = min(n),
           max = max(n))

N_ratings_per_word <- ratings %>%
    count(word) %>%
    summarize(min = min(n),
              max = max(n), 
              mean = mean(n),
              sd = sd(n))  %>%
  mutate_all(round, 2)

by_word_means <- ratings %>% 
  group_by(word) %>%
  summarize(mean_rating = mean(rating)) %>%
  ungroup() 
```

```{r}
GENDER_RATINGS_CI_PATH <- here("data/processed/words/gender_ratings_mean.csv")
gender_ratings_with_ci <- read_csv(GENDER_RATINGS_CI_PATH)

perc_gendered <- gender_ratings_with_ci %>%
  count(gender_bias) %>%
  mutate(percentage = round(n/sum(n) * 100,0))
```


```{r}
CORPUS_PATH <- here('data/processed/books/tidy_full_corpus_all.csv')
tidy_corpus <- read_csv(CORPUS_PATH) %>%
  filter(!(book_id %in% c("L105", "L112"))) # "Journey" and "Anno's Journey" are pictures books

GLASGOW_NORMS_PATH <- here("data/processed/words/glasgow_norms.csv")
glasgow_norms <- read_csv(GLASGOW_NORMS_PATH) %>%
  select(word, GEND_M) %>%
  rename(glasgow_gender = GEND_M)

STOP_WORDS_PATH <- here("data/raw/other/stop_words.csv") # stop words come from https://github.com/igorbrigadir/stopwords/blob/master/en/ranksnl_oldgoogle.txt
stop_words <- read_csv(STOP_WORDS_PATH) 

mean_rating_no_sense <- by_word_means %>%
  mutate(word = map_chr(word, ~unlist(str_split(.x, " "))[[1]])) %>%
  group_by(word) %>%
  summarize(gender = mean(mean_rating)) %>%
  left_join(glasgow_norms)

normed_tokens <- tidy_corpus %>%
  left_join(mean_rating_no_sense) %>%
  anti_join(stop_words) %>%
  mutate(normed_word = ifelse(!is.na(gender), TRUE, FALSE)) %>%
  count(normed_word) %>%
  mutate( prop_normed = n/sum(n),
          percent_normed = glue("{round(prop_normed * 100,2)}%")) %>%
  filter(normed_word)

prop_token_normed_by_book <- tidy_corpus %>%
  left_join(mean_rating_no_sense) %>%
  anti_join(stop_words) %>%
  group_by(book_id) %>%
  mutate(normed_word = ifelse(!is.na(gender), TRUE, FALSE)) %>%
  summarize(prop_normed = sum(normed_word)/n(),
            n = n()) %>%
  arrange(prop_normed) # min > 30%

mean_per_book_normed <- round(mean(prop_token_normed_by_book$prop_normed) *100,2)
sd_per_book_normed <- round(sd(prop_token_normed_by_book$prop_normed)*100,2)

prop_type_normed_by_book <- tidy_corpus %>%
  left_join(mean_rating_no_sense) %>%
  anti_join(stop_words) %>%
  group_by(book_id) %>%
  distinct(word, .keep_all = T) %>%
  mutate(normed_word = ifelse(!is.na(gender), TRUE, FALSE)) %>%
  summarize(prop_normed = sum(normed_word)/n(),
            n = n()) %>%
  arrange(prop_normed)

mean_type_per_book_normed <- round(mean(prop_type_normed_by_book$prop_normed) *100,2)
sd_type_per_book_normed <- round(sd(prop_type_normed_by_book$prop_normed)*100,2)
```

```{r pos}
NORMED_WORDS_WITH_POS <- here("data/processed/words/normed_words_pos.csv")
pos_of_normed_words <- read_csv(NORMED_WORDS_WITH_POS)

pos_dist <- pos_of_normed_words %>%
  mutate(pos = case_when(dom_po_s_subtlex %in% c("Adjective","Adverb") ~ "adj/adv",
                         dom_po_s_subtlex == "Verb" ~ "verb",
                        dom_po_s_subtlex %in% c("Noun","Name") ~ "noun",
                        TRUE ~ "other")) %>%
    count(pos) %>%
    mutate(perc = glue("{round(n/sum(n) * 100,2)}%"))

prop_verbs <- pos_dist %>%
  filter(pos == "verb") %>%
  pull(perc)

prop_noun <- pos_dist %>%
  filter(pos == "noun") %>%
  pull(perc)

```

Because it was infeasible to collect gender norms for all `r format(nrow(distinct(tidy_corpus, word)), big.mark = ",")` unique words, ratings were obtained for a large subset of the most important content-bearing words (_N_ = `r format(nrow(by_word_means), big.mark = ",")`). This subset was largely composed of nouns (`r prop_noun`) and verbs (`r prop_verbs`). We also included the names of all characters (e.g. "Amelia", "Yertle"). A short context was provided to indicate a specific meaning of homonyms, e.g., "pin (hold down)", "creep (move slowly)", "act (part of a play)", "act (to take action)". The norms included `r pull(normed_tokens, percent_normed)` of the tokens in the corpus excluding stop words, and at least 30% of the tokens in each book  (_M_ = `r mean_per_book_normed`%; _SD_ = `r sd_per_book_normed`%; types: _M_ = `r mean_type_per_book_normed`%; _SD_ = `r sd_type_per_book_normed`%).

Participants rated the gender of each word on a 1-5 scale with the intervals labeled “Very masculine,” “Somewhat masculine,” “Neither masculine nor feminine,” “Somewhat feminine,” and “Very feminine”. The instructions did not provide definitions of masculine or feminine; raters were encouraged to use their own intuitions. Each participant rated `r pull(N_ratings_per_subject, min)`-`r pull(N_ratings_per_subject, max)` words. Words were quasirandomly assigned to participants to ensure that each word received at least 10 ratings; mean number of ratings per word was `r pull(N_ratings_per_word, mean)` (_SD_ = `r N_ratings_per_word$sd`). 


### Results

```{r, cache = TRUE}
rating_summary_stats <- by_word_means %>%
  tidyboot_mean(column = mean_rating) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(print_mean = glue("[{ci_lower}, {ci_upper}]"))

by_gender_means <- ratings %>%
  left_join(rating_demos_ex %>%
  filter(question_name == "gender")) %>%
  rename(gender = response_str) %>%
  group_by(word, gender) %>%
  summarize(mean_rating = mean(rating))  %>%
  spread(gender, mean_rating) %>%
  ungroup()

male_vs_female_participants_summary <- by_gender_means %>%
  gather("group", "value", -word) %>%
  group_by(group) %>%
  tidyboot_mean(column = value, na.rm = T) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(print_mean = glue("_M_ = {mean} [{ci_lower}, {ci_upper}]"))

male_vs_female_participants_t <- t.test(by_gender_means$female, by_gender_means$male, paired = T) %>%
  tidy()

male_vs_participants_d <- mes(mean(by_gender_means$female), mean(by_gender_means$male), 
    sd(by_gender_means$female), sd(by_gender_means$male),
    length(by_gender_means$female), length(by_gender_means$male), verbose = F) %>%
  select(d, l.d, u.d) %>%
  mutate(male_vs_participants_d_print = glue("{d} [{l.d}, {u.d}]")) %>%
  pull(male_vs_participants_d_print)
```

```{r mean_word_ratings}
# comparision to glasgow
num_in_glasgow <- mean_rating_no_sense %>%
  filter(!is.na(glasgow_gender)) %>%
  nrow()

glasgow_cor <- mean_rating_no_sense %>%
  mutate(glasgow_gender = -glasgow_gender) %>% # glasgow/us have different scale directions
  get_tidy_corr_text("gender", "glasgow_gender") 

# example words
TARG_WORDS <- c("sir", "uncle", "fireman", "barber", "cute", "dame", "dress", "prettiest", "carry", "exactly", "letter", "nose")

targ_word_ratigns <- mean_rating_no_sense %>%
 arrange(gender) %>%
 mutate(nth_gender = (1:n())/n()) %>%
 filter(word %in% TARG_WORDS)
```


The overall mean gender rating was very close to the midpoint `r pull(rating_summary_stats, mean)` (`r pull(rating_summary_stats, print_mean)`); `r filter(perc_gendered, gender_bias == "f") %>% pull(percentage)`% of the words were significantly female biased (larger than the overall mean; *p* < .05) and 24% significantly male biased (*p* < .05). There was a marginal effect of participant gender: female participants (`r male_vs_female_participants_summary %>% filter(group == "female") %>% pull(print_mean)`) rated words as more feminine on average compared to male raters (`r male_vs_female_participants_summary %>% filter(group == "male") %>% pull(print_mean)`; paired *t*-test: _t_(`r male_vs_female_participants_t$parameter`) = `r male_vs_female_participants_t$statistic`; _p_ = `r male_vs_female_participants_t$p.value`; *d* = `r male_vs_participants_d`). Gender ratings for `r prettyNum(num_in_glasgow, big.mark = ",")` of our words were also obtained by @scott2019glasgow and the two sets of ratings were highly correlated, `r glasgow_cor`. To explore the data interactively, go to https://mlewis.shinyapps.io/SI_WCBC_GENDER/. See SI for analyses of the relationship between gender ratings and other word properties (frequency, concreteness, arousal, valence, and age of acquisition).

```{r}
LABEL_DATA <- here("data/processed/words/cluster_labels.csv")
cluster_labels <- read_csv(LABEL_DATA)

TNSE_DATA <- here("data/processed/words/gender_centroids_tsne_coordinates.csv")
centroid_df <- read_csv(TNSE_DATA)  %>%
    left_join(cluster_labels)  %>%
    select(cluster_id, n, effect_size, eff_conf_low, eff_conf_high, 
           cluster_label, gender_bias)

gender_bias_counts <- count(centroid_df, gender_bias)
```


```{r clusterexamples,  results = 'asis'}
target_clusters <- c("zoo animals", "airborne actions", "tools", "professions",
                     "transportation (ground)", "communication verbs", "affection",
                     "modifiers", "school", "food",
                     "body parts", "spatial terms", "family relationships", "house parts",
                     "quantifiers")

target_cluster_df <- centroid_df %>%
  filter(cluster_label %in% target_clusters) %>%
  arrange(effect_size)

cluster_examples <- tibble(cluster_id = c(75, 50, 17, 97, 86, 89, 24, 96, 23, 13,
                                          68, 71, 43, 36, 33),
       example_words = c("judge, policemen, guard, sailor, mayor, clerk",
                         "car, bicycle, trains, ambulance, engine, traffic",
                         "axe, blade, knife, bow, stick, wood",
                         "climbed, tossed, jumped, knocked, pulled, swung",
                         "giraffe, elephant, gorilla, lion, monkey, zebra",
                         "meatballs, soup, eggs, milk, pie, salad",
                         "learning, practicing, school, students, writing, book",
                         "spoke, listened, heard, explained, asked, answered",
                         "probably, whenever, truly, likely, completely, yet",
                         "kisses, loved, smile, tears, heart, care",
                         "across, long, low, through, close",
                         "few, almost, many, most, whole",
                         "bedroom, floor, lamp, roof, window",
                         "eye, knee, ankle, hair, bone",
                         "children, brother, sister, uncle, aunt")) %>%
  left_join(target_cluster_df) %>%
  mutate(gender_bias = fct_relevel(gender_bias, "female", "neither")) %>%
  arrange(gender_bias, -effect_size)%>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(ES_string = paste0(effect_size, " [", eff_conf_low, ", ", eff_conf_high,
                            "]")) %>%
  select(cluster_label, ES_string, n, example_words) 

kable(cluster_examples,  "latex", booktabs = T,  escape = F, longtable = F,
      caption = "Examples of Clusters from Multi-Dimensional Embeddings",
      col.names = linebreak(c("Category", "Effect Size", "$N$", "Examples"))) %>%
  kable_styling(latex_options = c("scale_down")) %>%
  pack_rows("Female-Biased Clusters", 1, 5) %>%
  pack_rows("Neutral Clusters", 6, 10) %>%
  pack_rows("Male-Biased Clusters", 11, 15)  %>%
  footnote(general = "Effect size measure is Cohen's $d$ based on a one-sample $t$-test comparing the mean gender of words in a cluster to the overall word gender mean. Clustering is an unsupervised machine learning method for dividing observations into k clusters by minimizing within-cluster distance and maximizing across-cluster distance. Brackets give bootstrapped 95 percent confidence intervals. $N$ indicates number of words in each cluster.", general_title = "Note:", footnote_as_chunk = T, threeparttable = T, escape = F)

```

To examine the kinds of words rated as masculine or feminine we identified semantic neighborhoods of words using a word embedding model [@mikolov2013efficient]. Such models generate semantic representations of words based on co-occurrences in a text corpus, on the assumption that words that occur in similar contexts are similar in meaning [@landauer1997solution]. Semantic representations extracted in this way capture important aspects of meaning and correlate with human judgments of semantic similarity [@hill2015simlex], although not without limitations [@chen2017evaluating]. We obtained semantic coordinates for each word in our sample (a 300 dimensional vector) from a word embedding model pre-trained on English Wikipedia  [@bojanowski2016enriching], and reduced the dimensionality of these coordinates to two using the t-SNE algorithm [t-SNE is similar to PCA but better suited for high-dimensional spaces; @maaten2008visualizing]. We then obtained 100 clusters of words based on their coordinates using k-means clustering.  We determined the gender bias of each cluster by comparing the mean rated genderedness of the words in the cluster to the mean rated genderedness of all words in our sample.

The clustering procedure yielded semantically coherent clusters with each containing an  average of `r mean(centroid_df$n)` words (_SD_ = `r sd(centroid_df$n)`). Of the 100 clusters, `r filter(gender_bias_counts, gender_bias == "female") %>% pull(n)`  were female-biased, `r filter(gender_bias_counts, gender_bias == "male") %>% pull(n)` were male-biased, and the remaining `r prettyNum(filter(gender_bias_counts, gender_bias == "neither") %>% pull(n), big.mark = ",")` were neutral. \autoref{tab:clusterexamples} shows examples of female-biased, male-biased and neutral clusters along with representative words (see SI for complete results). Many of the gendered clusters instantiate gender stereotypes. Female clusters were associated with mental states (e.g., feelings, beliefs) and interactions with others (e.g., communicating, caregiving). Male clusters were more closely associated with physical rather than mental events (e.g., sports, tools, transportation). These findings indicate that clusters of semantically-related words in these texts are associated with gender, many reflecting gender stereotypes. 
