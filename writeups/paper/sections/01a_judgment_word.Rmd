```{r}
library(tidyverse)
library(here)
library(janitor)
options(knitr.table.format = "latex")
```

# Study 1: Measuring gender bias with human judgments

## Study 1a: Gender bias in words
As a first step in understanding the genderedness of words in the book corpus, we had adult English speakers rate words on genderedness using a 5-point scale from masculine to feminine [@scott2019glasgow]. These ratings were quite systematic; words such as *cuddle* and *pink* were rated as feminine, *axe* and *engine* as masculine, and *exactly* and *nose* as neutral.


### Method

```{r}
RATING_DEMO_PATH <- here("data/processed/words/gender_ratings_demographics.csv")
EXCLUDED_TURKERS_PATH <-  here("data/processed/words/n_participants_attention_excluded.csv")

num_excluded_attention_check <- read_csv(EXCLUDED_TURKERS_PATH) %>%
  pull(num_excluded_attention_check)

num_excluded_midpoint <- read_csv(EXCLUDED_TURKERS_PATH) %>%
  pull(num_excluded_midpoint)

rating_demos <- read_csv(RATING_DEMO_PATH)

non_native_participants <- rating_demos %>%
  filter(question_name == "native_english" | question_name == "native") %>%
  filter(response_str == 0) %>%
  pull(subj_id)

rating_demos_ex <- rating_demos %>%
  filter(!(subj_id %in% non_native_participants))

gender_data <- rating_demos_ex %>%
  filter(question_name == "gender") %>%
  count(response_str)

age_mean <- rating_demos_ex %>%
  filter(question_name == "age")  %>%
  mutate(response_str = as.numeric(response_str)) %>%
  summarize(
    sd_age = sd(response_str, na.rm = T),
    mean_age = mean(response_str, na.rm = T)) %>%
  mutate_if(is.numeric, round, 1)

edu_data <- rating_demos_ex %>%
  filter(question_name == "education") %>%
  mutate(response_str = as.factor(response_str)) %>%
  rename(edu = response_str) %>%
  select(-question_name)
``` 


Participants (_N_ = `r length(unique(rating_demos_ex$subj_id)) + length(non_native_participants) + num_excluded_attention_check + num_excluded_midpoint`) were recruited on Amazon Mechanical Turk. Participants who answered any of 6 performance integrity check items incorrectly (e.g., “The word red has two letters”) were excluded  (_N_ = `r num_excluded_attention_check`). We also excluded `r num_excluded_midpoint` participant who responded with the midpoint on almost all items, and 6 non-native English speakers. The final sample included `r length(unique(rating_demos_ex$subj_id))` participants (`r filter(gender_data, response_str == "male")$n`  who identified as male, `r filter(gender_data, response_str == "female")$n` female, and `r filter(gender_data, response_str == "other")$n` other), with a mean age of `r printnum(pull(age_mean,mean_age))` years (_SD_ = `r printnum(pull(age_mean,sd_age))`).\footnote{All data and code available in a public repository: \url{https://github.com/mllewis/WCBC_GENDER}}


```{r stimuli}
RATING_RATINGS_PATH <- here("data/processed/words/gender_ratings.csv")
ratings <- read_csv(RATING_RATINGS_PATH, col_names = TRUE, 
                    cols(subj_id = "c", word = "c", rating = "n")) %>%
  filter(!(subj_id %in% non_native_participants))


N_ratings_per_subject <- ratings %>%
  count(subj_id) %>%
  summarize(min = min(n),
           max = max(n))

N_ratings_per_word <- ratings %>%
    count(word) %>%
    summarize(min = min(n),
              max = max(n), 
              mean = mean(n),
              sd = sd(n))  %>%
  mutate_all(round, 2)

by_word_means <- ratings %>% 
  group_by(word) %>%
  summarize(mean_rating = mean(rating)) %>%
  ungroup() 
```

```{r}
GENDER_RATINGS_CI_PATH <- here("data/processed/words/gender_ratings_mean.csv")
gender_ratings_with_ci <- read_csv(GENDER_RATINGS_CI_PATH)

perc_gendered <- gender_ratings_with_ci %>%
  count(gender_bias) %>%
  mutate(percentage = round(n/sum(n) * 100,0))
```


```{r}
CORPUS_PATH <- here('data/processed/books/tidy_full_corpus_all.csv')
tidy_corpus <- read_csv(CORPUS_PATH) 

GLASGOW_NORMS_PATH <- here("data/processed/words/glasgow_norms.csv")
glasgow_norms <- read_csv(GLASGOW_NORMS_PATH) %>%
  select(word, GEND_M) %>%
  rename(glasgow_gender = GEND_M)

STOP_WORDS_PATH <- here("data/raw/other/stop_words.csv") # stop words come from https://github.com/igorbrigadir/stopwords/blob/master/en/ranksnl_oldgoogle.txt
stop_words <- read_csv(STOP_WORDS_PATH) 

mean_rating_no_sense <- by_word_means %>%
  mutate(word = map_chr(word, ~unlist(str_split(.x, " "))[[1]])) %>%
  group_by(word) %>%
  summarize(gender = mean(mean_rating)) %>%
  left_join(glasgow_norms)

normed_tokens <- tidy_corpus %>%
  left_join(mean_rating_no_sense) %>%
  anti_join(stop_words) %>%
  mutate(normed_word = ifelse(!is.na(gender), TRUE, FALSE)) %>%
  count(normed_word) %>%
  mutate( prop_normed = n/sum(n),
          percent_normed = glue("{round(prop_normed * 100,2)}%")) %>%
  filter(normed_word)

prop_token_normed_by_book <- tidy_corpus %>%
  left_join(mean_rating_no_sense) %>%
  anti_join(stop_words) %>%
  group_by(book_id) %>%
  mutate(normed_word = ifelse(!is.na(gender), TRUE, FALSE)) %>%
  summarize(prop_normed = sum(normed_word)/n(),
            n = n()) %>%
  arrange(prop_normed) # min > 30%

mean_per_book_normed <- round(mean(prop_token_normed_by_book$prop_normed) *100,2)
sd_per_book_normed <- round(sd(prop_token_normed_by_book$prop_normed)*100,2)
```

```{r pos}
NORMED_WORDS_WITH_POS <- here("data/processed/words/normed_words_pos.csv")
pos_of_normed_words <- read_csv(NORMED_WORDS_WITH_POS)

pos_dist <- pos_of_normed_words %>%
  mutate(pos = case_when(dom_po_s_subtlex %in% c("Adjective","Adverb") ~ "adj/adv",
                         dom_po_s_subtlex == "Verb" ~ "verb",
                        dom_po_s_subtlex %in% c("Noun","Name") ~ "noun",
                        TRUE ~ "other")) %>%
    count(pos) %>%
    mutate(perc = glue("{round(n/sum(n) * 100,2)}%"))

prop_verbs <- pos_dist %>%
  filter(pos == "verb") %>%
  pull(perc)

prop_noun <- pos_dist %>%
  filter(pos == "noun") %>%
  pull(perc)

```

Because it was not feasible to collect gender norms for all `r format(nrow(distinct(tidy_corpus, word)), big.mark = ",")` unique words, ratings were obtained for a large subset of the most important words (_N_ = `r format(nrow(by_word_means), big.mark = ",")`). The normed word set excluded stop words (_N_ = 30), and was largely comprised of nouns (`r prop_noun`) and verbs (`r prop_verbs`).   We also included the names of all the characters (e.g. “Grover,” “Amelia”, “Yertle”). A short context was provided to indicate a specific meaning of homonymous words, e.g., “pin (hold down),” “creep (move slowly),” “act (part of a play),” “act (to take action)." `r pull(normed_tokens, percent_normed)` of the tokens in the corpus and at least 30% of the tokens in each book were normed (_M_ = `r mean_per_book_normed`; _SD_ = `r sd_per_book_normed`; excluding stop words).

Participants were instructed to rate the gender of each word on a 1-5 scale with the intervals labeled “Very masculine,” “Somewhat masculine,” “Neither masculine nor feminine,” “Somewhat feminine,” and “Very feminine”. The instructions did not provide explicit definitions of masculine or feminine; raters were encouraged to base ratings on their own intuitions. Each participant rated between `r pull(N_ratings_per_subject, min)` and `r pull(N_ratings_per_subject, max)` words. Words were quasirandomly assigned to participants to ensure that each word received at least 10 ratings; mean number of ratings per word was `r pull(N_ratings_per_word, mean)` (_SD_ = `r N_ratings_per_word$sd`). 


### Results

```{r, cache = TRUE}
rating_summary_stats <- by_word_means %>%
  tidyboot_mean(column = mean_rating) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(print_mean = glue("[{ci_lower}, {ci_upper}]"))

by_gender_means <- ratings %>%
  left_join(rating_demos_ex %>%
  filter(question_name == "gender")) %>%
  rename(gender = response_str) %>%
  group_by(word, gender) %>%
  summarize(mean_rating = mean(rating))  %>%
  spread(gender, mean_rating) %>%
  ungroup()

male_vs_female_participants_summary <- by_gender_means %>%
  gather("group", "value", -word) %>%
  group_by(group) %>%
  tidyboot_mean(column = value, na.rm = T) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(print_mean = glue("_M_ = {mean} [{ci_lower}, {ci_upper}]"))

male_vs_female_participants_t <- t.test(by_gender_means$female, by_gender_means$male, paired = T) %>%
  tidy()

male_vs_participants_d <- mes(mean(by_gender_means$female), mean(by_gender_means$male), 
    sd(by_gender_means$female), sd(by_gender_means$male),
    length(by_gender_means$female), length(by_gender_means$male), verbose = F) %>%
  select(d, l.d, u.d) %>%
  mutate(male_vs_participants_d_print = glue("{d} [{l.d}, {u.d}]")) %>%
  pull(male_vs_participants_d_print)
```

```{r mean_word_ratings}
# comparision to glasgow
num_in_glasgow <- mean_rating_no_sense %>%
  filter(!is.na(glasgow_gender)) %>%
  nrow()

glasgow_cor <- mean_rating_no_sense %>%
  mutate(glasgow_gender = -glasgow_gender) %>% # glasgow/us have different scale directions
  get_tidy_corr_text("gender", "glasgow_gender") 

# example words
TARG_WORDS <- c("sir", "uncle", "fireman", "barber", "cute", "dame", "dress", "prettiest", "carry", "exactly", "letter", "nose")

targ_word_ratigns <- mean_rating_no_sense %>%
 arrange(gender) %>%
 mutate(nth_gender = (1:n())/n()) %>%
 filter(word %in% TARG_WORDS)
```

The overall mean gender rating was  `r pull(rating_summary_stats, mean)` (`r pull(rating_summary_stats, print_mean)`), i.e., very close to the midpoint. `r filter(perc_gendered, gender_bias == "f") %>% pull(percentage)`% of the words were significantly female biased, `r filter(perc_gendered, gender_bias == "m") %>% pull(percentage)`% significantly male biased, and the remaining did not differ from the overall mean gender rating. There was a numerically small, marginal effect of participant gender. Female participants  (`r male_vs_female_participants_summary %>% filter(group == "female") %>% pull(print_mean)`) rated words as more feminine on average compared to male raters (`r male_vs_female_participants_summary %>% filter(group == "male") %>% pull(print_mean)`; paired *t*-test: _t_(`r male_vs_female_participants_t$parameter`) = `r male_vs_female_participants_t$statistic`; _p_ = `r male_vs_female_participants_t$p.value`; *d* = `r male_vs_participants_d`). Gender ratings for   `r prettyNum(num_in_glasgow, big.mark = ",")` of our words were also obtained by @scott2019glasgow  and the two sets of ratings are highly correlated, `r glasgow_cor`. Data can be explored interactively at https://mlewis.shinyapps.io/SI_WCBC_GENDER/.  See SI for analyses of the relationship between word gender ratings and other word properties, such as concreteness and frequency.


```{r}
LABEL_DATA <- here("data/processed/words/cluster_labels.csv")
cluster_labels <- read_csv(LABEL_DATA)

TNSE_DATA <- here("data/processed/words/gender_centroids_tsne_coordinates.csv")
centroid_df <- read_csv(TNSE_DATA)  %>%
    left_join(cluster_labels)  %>%
    select(cluster_id, n, effect_size, eff_conf_low, eff_conf_high, 
           cluster_label, gender_bias)

gender_bias_counts <- count(centroid_df, gender_bias)
```


```{r clusterexamples,  results = 'asis'}
target_clusters <- c("zoo animals", "airborne actions", "tools", "professions",
                     "transportation (ground)", "communication verbs", "affection",
                     "modifiers", "school", "food",
                     "body parts", "spatial terms", "family relationships", "house parts",
                     "quantifiers")

target_cluster_df <- centroid_df %>%
  filter(cluster_label %in% target_clusters) %>%
  arrange(effect_size)

cluster_examples <- tibble(cluster_id = c(75, 50, 17, 97, 86, 89, 24, 96, 23, 13,
                                          68, 71, 43, 36, 33),
       example_words = c("judge, policemen, guard, sailor, mayor, clerk",
                         "car, bicycle, trains, ambulance, engine, traffic",
                         "axe, blade, knife, bow, stick, wood",
                         "climbed, tossed, jumped, knocked, pulled, swung",
                         "giraffe, elephant, gorilla, lion, monkey, zebra",
                         "meatballs, soup, eggs, milk, pie, salad",
                         "learning, practicing, school, students, writing, book",
                         "spoke, listened, heard, explained, asked, answered",
                         "probably, whenever, truly, likely, completely, yet",
                         "kisses, loved, smile, tears, heart, care",
                         "across, long, low, through, close",
                         "few, almost, many, most, whole",
                         "bedroom, floor, lamp, roof, window",
                         "eye, knee, ankle, hair, bone",
                         "children, brother, sister, uncle, aunt")) %>%
  left_join(target_cluster_df) %>%
  mutate(gender_bias = fct_relevel(gender_bias, "female", "neither")) %>%
  arrange(gender_bias, -effect_size)%>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(ES_string = paste0(effect_size, " [", eff_conf_low, ", ", eff_conf_high, "]")) %>%
  select(cluster_label, ES_string, n, example_words) 

kable(cluster_examples,  "latex", booktabs = T,  escape = F, longtable = F,
      caption = "Examples of Clusters from Multi-Dimensional Embeddings",
      col.names = linebreak(c("Category", "Effect Size", "$N$", "Examples"))) %>%
  kable_styling(latex_options = c("scale_down")) %>%
  pack_rows("Female-Biased Clusters", 1, 5) %>%
  pack_rows("Neutral Clusters", 6, 10) %>%
  pack_rows("Male-Biased Clusters", 11, 15)  %>%
  footnote(general = "Effect size measure is Cohen's $d$ based on a one-sample $t$-test comparing the mean gender of words in a cluster to the overall word gender mean. Brackets give bootstrapped 95 percent confidence intervals. $N$ indicates number of words in each cluster.", general_title = "Note:", footnote_as_chunk = T, threeparttable = T, escape = F)

```

What kinds of word meanings tend be rated as masculine or feminine? To answer this question, we identified the semantic neighborhoods of words in our sample using a word embedding model [@mikolov2013efficient]. Word embedding models provide a semantic representation of a word based on patterns of co-occurrence in a corpus of text, characterizing words as similar to the extent that they occur in similar contexts [“distributional statistics”; e.g., @landauer1997solution]. Semantic representations extracted in this way capture important aspects of meaning and correlate with human judgments of semantic similarity [@hill2015simlex], though not without limitations [@chen2017evaluating]. We obtained semantic coordinates for each word in our sample (a 300 dimensional vector) from a word embedding model pre-trained on English Wikipedia [@bojanowski2016enriching], and then reduced the dimensionality of these coordinates to two using the t-sne algorithm [an algorithm similar to PCA but better suited for high-dimensional spaces; @maaten2008visualizing]. Finally, we clustered the words into 100 clusters based on their coordinates using k-means clustering. Clustering is an unsupervised machine learning method for dividing observations into *k* clusters by minimizing within-cluster distance and maximizing across-cluster distance. We determined the gender bias of each cluster by comparing the mean gender bias of words in that cluster to the gender bias of all words in our sample. 

The clustering procedure yielded semantically coherent clusters with an average of  `r mean(centroid_df$n)` words (_SD_ = `r sd(centroid_df$n)`) per cluster (\autoref{tab:clusterexamples}; see  SI for complete results). The average rated genderedness of the words in these clusters was calculated using the gender norms. For each word cluster, we tested whether the mean gender rating of words in that cluster significantly differed from the overall mean gender rating of words. Of the 100 clusters, `r filter(gender_bias_counts, gender_bias == "female") %>% pull(n)`  were female-biased, `r filter(gender_bias_counts, gender_bias == "male") %>% pull(n)` were male-biased, and the remaining `r prettyNum(filter(gender_bias_counts, gender_bias == "neither") %>% pull(n), big.mark = ",")` were neutral. Table 3 shows examples of female-biased, male-biased and neutral clusters along with representative words. The gendered clusters differ in ways that reflect gender stereotyping. For example, female clusters were associated with mental states (feelings, beliefs) and interactions with others (communicating, caregiving). Male clusters, in contrast, tended to be more closely associated with events in the physical realm (e.g., sports, tools, transportation). Further, these findings suggest that gender is an organizing dimension of semantic space for words found in children's books: Meanings semantically similiar to each other tend to have similiar gender associations.
