## Study 1c: Validation of book gender bias measure

We estimated  each  book’s gender bias using a simple average of the gender bias of the words comprising them.  Of course, the words actually occur in contexts that could modulate their bias. For example, the gender bias of “brave” would be the same whether it occurred in the sentence “Sally is brave” or “Sally is not brave”. To address this concern, we asked a new group of adult participants to provide information about main characters after reading the complete text of a book. We could then determine whether these participant-generated descriptions exhibited the gender biases identified using the simpler word-based measure. The two should diverge if book genderedness as estimated by averaging isolated words is unrepresentative of the story context.

### Method

```{r}
META_DATA <- here("data/processed/character_norming/exp1/exp1_meta_data.csv")
meta_data <- read_csv(META_DATA)

by_gender_counts <- meta_data %>%
  count(gender)
```

We recruited `r nrow(meta_data)` participants from Amazon Mechanical Turk. `r by_gender_counts %>% filter(gender == "female") %>% pull(n) %>% as.english() %>% str_to_sentence()` identified as female, `r by_gender_counts %>% filter(gender == "male") %>% pull(n)` identified as male, `r by_gender_counts %>% filter(is.na(gender)) %>% pull(n)` did not provide a response.

```{r}
CLEANED_RESPONSES_DF <- here("data/processed/character_norming/exp1/exp1_response_data.csv")
cleaned_responses_with_norms <- read_csv(CLEANED_RESPONSES_DF) %>%
    mutate(gender_group = fct_relevel(gender_group, "male-biased", "neutral")) 

```

```{r}
BOOK_MEANS_PATH <- here("data/processed/books/gender_token_type_by_book.csv")
study1b_gender_means  <- read_csv(BOOK_MEANS_PATH)

gender_rating_by_book_mean_only <- study1b_gender_means %>%
  filter(corpus_type == "all") %>%
  select(book_id, token_gender_mean)

# mean gender bias by book group
normed_books_bias <- cleaned_responses_with_norms %>%
  distinct(book_id, gender_group, title) %>%
  left_join(gender_rating_by_book_mean_only) %>%
  group_by(gender_group) %>%
  summarize(mean = mean(token_gender_mean),
            sd = sd(token_gender_mean)) %>%
  mutate_if(is.numeric, round,2) %>%
  mutate(print_summary = glue("*M* =  {mean}; *SD* = {sd}"))
```

```{r, evaluate = F, include = F}
# get examples
 cleaned_responses_with_norms %>% 
  filter(gender_group == "male-biased", question_type == "description") %>% 
  group_by(word_tidy_lemma) %>%
  summarize(n = n(),
            human_gender_estimate_us = mean(human_gender_estimate_us)) %>%
  arrange(-n) %>%
  slice(1:15) %>% 
  arrange(-human_gender_estimate_us) %>%
  data.frame()

# examples in exp: "pretty", "loud", or "clever."
# get examples
 cleaned_responses_with_norms %>% 
  filter(gender_group == "female-biased", question_type == "activity") %>% 
  group_by(word_tidy_lemma) %>%
  summarize(n = n(),
            human_gender_estimate_us = mean(human_gender_estimate_us)) %>%
  arrange(-n) %>%
  slice(1:15) %>% 
  arrange(-human_gender_estimate_us) %>%
  data.frame()


# examples in exp:  "run", "play", or "eat."


```
We divided the books in our corpus into quintiles based on the average gender score described in Study 1b, and selected 15 books each from the first (female-biased: `r normed_books_bias %>% filter(gender_group == "female-biased") %>% pull(print_summary)`), third  (neutral: `r normed_books_bias %>% filter(gender_group == "neutral") %>% pull(print_summary)`), and fifth quintiles (male-biased: `r normed_books_bias %>% filter(gender_group == "male-biased") %>% pull(print_summary)`) to be evaluated. We excluded books that were either very short or very long (less than 100 words, or more than 900 words), or those without a gendered main character.

Participants were presented with the complete text of a book, and told that they would be asked questions about the characters in it. After reading the text, participants were asked to list 2-5 main activities of a specified character (e.g., “List 2-5 main activities *Thomas* does in the story."). The full text of the book was displayed on the same page so that participants did not have to rely on memory to answer the question. Next, participants were asked to complete a similar procedure but provide descriptions of the character’s traits (e.g., “List 2-5 words to describe *Thomas* in the story."). This procedure was repeated for all main and secondary characters in a book. Each participant provided responses for both character activities and character traits for three books.

```{r}
n_judgments <- cleaned_responses_with_norms %>%
  group_by(participant_id, book_id, character_name,  question_type) %>%
  count()

mean_n_response <- round(mean(n_judgments$n),2)
sd_n_response <- round(sd(n_judgments$n),2)

cleaned_responses_with_norms_filtered <- cleaned_responses_with_norms %>%
  filter(correct_pos %in% c("action", "description"))  %>% # action = verb; description = noun, adjective, adverb
  mutate(nchar = nchar(raw_response)) %>%
  filter(nchar < 35) # remove responses 35 chars or more (tend to be full sentences) 

percent_exclude <- round(((nrow(cleaned_responses_with_norms) - nrow(cleaned_responses_with_norms_filtered))/nrow(cleaned_responses_with_norms)) * 100, 0) 
unique_types <- length(unique(cleaned_responses_with_norms_filtered$word_tidy_lemma))
```

```{r}
num_ratings <- cleaned_responses_with_norms_filtered %>%
  mutate(missing_human = is.na(human_gender_estimate_us)) %>%
  count(missing_human) 

num_ratings_present <- num_ratings %>% 
  filter(!missing_human) %>%
  pull(n)

num_ratings_absent <- num_ratings %>% 
  filter(missing_human) %>%
  pull(n)

percent_with_norms <- round((num_ratings_present/(num_ratings_present + num_ratings_absent)) * 100, 2)
```

```{r normingsample}
coverage_tokens <- cleaned_responses_with_norms_filtered %>%
  select(word_tidy_lemma, source) %>%
  count(source) %>%
  mutate(prop = n/sum(n))

original_coverage <- coverage_tokens %>%
  filter(source == "first_sample") %>%
  pull(prop)

GENDER_BIAS_DESC_ACT <- here("data/processed/words/gender_ratings_desc_act_mean.csv") # supplemental words we normed

gender_bias_estimates_desc_act <- read_csv(GENDER_BIAS_DESC_ACT) 

sample_two_desc <- gender_bias_estimates_desc_act %>%
  summarize(mean_n = mean(n),
            sd_n = sd(n)) %>%
  mutate_all(round, 2)

sample_two_words_per_participant <- mean(gender_bias_estimates_desc_act$n)

total_coverage <- coverage_tokens %>%
  mutate(total_perc = round(cumsum(prop)*100,0)) %>%
  filter(source == "second_sample") %>%
  pull(total_perc)
```

On average, participants generated `r mean_n_response` responses per question (*SD* = `r sd_n_response`).  Responses were lemmatized, corrected for spelling, and, in cases where a multi-word phrase  was listed (e.g., “builds a castle”), the first word was selected for analysis. We identified the part of speech for the first word and excluded responses of the wrong class, analyzing only verbs for the activity question and adjectives, adverbs, and nouns for the trait question. We also excluded responses that were very long (more than 35 characters), as these were likely to be full sentences rather than activity or trait words. In total, `r percent_exclude`% of responses were excluded, leading to a final sample of `r prettyNum(nrow(cleaned_responses_with_norms_filtered), big.mark = ",")` responses and `r unique_types` unique lemmas.  We then analyzed the gender bias of the activity and trait words using previously-collected human judgments of word gender bias, which covered `r round(original_coverage*100,0)`% of the word tokens used to describe characters and their activities. We collected an additional set of human judgments (_N_ = `r nrow(gender_bias_estimates_desc_act)`; _M_ = `r sample_two_desc$mean_n` ratings/word; _SD_ = `r sample_two_desc$sd_n`) such that gender bias estimates were available for all words produced more than once in Study 1c (`r total_coverage`% of tokens; see SI). 

### Results


```{r}

# char
gender_rating_by_book_mean_only_char_only <- study1b_gender_means %>%
  filter(corpus_type == "char_only") %>%
  select(book_id, token_gender_mean) %>%
  rename(token_gender_mean_char = token_gender_mean)

# content
gender_rating_by_book_mean_only_no_char <- study1b_gender_means %>%
  filter(corpus_type == "no_char") %>%
  select(book_id, token_gender_mean) %>%
  rename(token_gender_mean_content = token_gender_mean)

cleaned_responses_with_norms_filtered_scaled <- cleaned_responses_with_norms_filtered %>%
  left_join(gender_rating_by_book_mean_only) %>%
  left_join(gender_rating_by_book_mean_only_char_only) %>%
  left_join(gender_rating_by_book_mean_only_no_char) %>%
  group_by(question_type) %>%
  mutate(human_gender_estimate_us_scaled = scale(human_gender_estimate_us),
         token_gender_mean_scaled = scale(token_gender_mean),
         token_gender_mean_char_scaled = scale(token_gender_mean_char),
         token_gender_mean_content_scaled = scale(token_gender_mean_content)) 


## all models
activity_model <- lmer(human_gender_estimate_us_scaled ~ token_gender_mean_scaled + (1|book_id) + (1|participant_id),
       data = cleaned_responses_with_norms_filtered_scaled %>% filter(question_type == "activity")) %>%
    tidy() %>%
    mutate_if(is.numeric, round, 2) %>%
    mutate(print_pretty = glue(" = {estimate}; *SE* = {std.error}; *t* = {statistic}"))

description_model <- lmer(human_gender_estimate_us_scaled ~  token_gender_mean_scaled + (1|book_id) + (1|participant_id),
     data = cleaned_responses_with_norms_filtered_scaled %>% filter(question_type == "description")) %>%
    tidy() %>%
    mutate_if(is.numeric, round, 2) %>%
    mutate(print_pretty = glue(" = {estimate}; *SE* = {std.error}; *t* = {statistic}"))

## char models
activity_model_char <- lmer(human_gender_estimate_us_scaled ~ token_gender_mean_char_scaled + (1|book_id) + (1|participant_id),
       data = cleaned_responses_with_norms_filtered_scaled %>% filter(question_type == "activity")) %>%
    tidy() %>%
    mutate_if(is.numeric, round, 2) %>%
    mutate(print_pretty = glue(" = {estimate}; *SE* = {std.error}; *t* = {statistic}"))

description_model_char <- lmer(human_gender_estimate_us_scaled ~ token_gender_mean_char_scaled + (1|book_id) + (1|participant_id),
       data = cleaned_responses_with_norms_filtered_scaled %>% filter(question_type == "description")) %>%
    tidy() %>%
    mutate_if(is.numeric, round, 2) %>%
    mutate(print_pretty = glue(" = {estimate}; *SE* = {std.error}; *t* = {statistic}"))

## content models
activity_model_content <- lmer(human_gender_estimate_us_scaled ~ token_gender_mean_content_scaled + (1|book_id) + (1|participant_id),
       data = cleaned_responses_with_norms_filtered_scaled %>% filter(question_type == "activity")) %>%
    tidy() %>%
    mutate_if(is.numeric, round, 2) %>%
    mutate(print_pretty = glue(" = {estimate}; *SE* = {std.error}; *t* = {statistic}"))

description_model_content <- lmer(human_gender_estimate_us_scaled ~ token_gender_mean_content_scaled + (1|book_id) + (1|participant_id),
       data = cleaned_responses_with_norms_filtered_scaled %>% filter(question_type == "description")) %>%
    tidy() %>%
    mutate_if(is.numeric, round, 2) %>%
    mutate(print_pretty = glue(" = {estimate}; *SE* = {std.error}; *t* = {statistic}"))

# SI - additional norm information to methods section of SI
```


```{r validationplot, fig.height = 4, fig.width = 5, fig.pos = "t", fig.cap = "Average genderedness of words generated in Study 1c to describe the main character's traits (triangles) and actions (circles). Error bars are bootstrapped 95\\% CIs."}
by_group_means <-  cleaned_responses_with_norms_filtered %>%
  mutate(gender_group = fct_relevel(gender_group, "male-biased", "neutral")) %>%
  filter(!is.na(human_gender_estimate_us)) %>%
  group_by(book_id, gender_group, question_type, participant_id) %>%
  summarize(mean_gender = mean(human_gender_estimate_us)) %>%
  group_by(book_id, gender_group, question_type) %>%
  summarize(mean_gender = mean(mean_gender)) %>%
  group_by(gender_group, question_type) %>%
  langcog::multi_boot_standard(col = "mean_gender")

label_df <- data.frame(label = c("actions", 
                                 "traits"),
                       x = c(3.35, 3.18),
                       y = c(3.18, 3.37))

ggplot(by_group_means, aes(x = gender_group, y = mean)) +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper, group = question_type), 
                  position = position_dodge(width = -0.3), size = .4) +
  geom_line(aes(group = question_type),
            position = position_dodge(width = -0.3)) +
  geom_point(aes(group = question_type, shape = question_type), 
             position = position_dodge(width = -0.3), size = 4) +
  geom_text(data = label_df, aes(x = x, y = y, label = label), size = 3) +
  scale_y_continuous(breaks = c(2.8, 3.0, 3.2, 3.4), 
                     label = c("2.8\n(male-\nbiased)",  "3.0" ,"3.2", "3.4\n(female-\nbiased)"),
                     limits = c(2.8, 3.49)) +
  ggtitle("Study 1c: Genderedness of main character\ntraits and actions") +
  ylab("Human judgment of word gender bias") +
  xlab("Book gender bias (word average)") +
  theme_classic(base_size = 12) +
  theme(legend.position = "none")
```

```{r, eval = F}
# ratio example for discussion

 cleaned_responses_with_norms %>%
   filter(question_type == "description", character_type == "m") %>%
   count(character_gender, word_tidy_lemma) %>%
   pivot_wider(names_from = "character_gender", values_from  = "n") %>%
   filter(f >= 2, m >= 2) %>%
   mutate(ratio = f/m) %>%
   arrange(-ratio)




```

The main question is whether the descriptions of book characters' traits and their actions generated by participants who read the books exhibited the same gender biases derived by averaging the gender scores for words in the texts. We fit mixed-effect linear regression models predicting the gender biases of characters’ traits and actions from the averaged word gender of a book. The averaged word gender of a book was treated as a continuous fixed effect, and book and participant were included as random intercepts.  The averaged word gender of a book predicted the gender bias of both the activity ($\beta$ `r activity_model %>% filter(term == "token_gender_mean_scaled") %>% pull(print_pretty)`) and trait words generated by participants ($\beta$ `r description_model %>% filter(term == "token_gender_mean_scaled") %>% pull(print_pretty)`; \autoref{fig:validationplot}). Averaged word gender based on exclusively content words predicted activity ($\beta$ `r activity_model_content %>% filter(term == "token_gender_mean_content_scaled") %>% pull(print_pretty)`) and trait words  ($\beta$ `r description_model_content %>% filter(term == "token_gender_mean_content_scaled") %>% pull(print_pretty)`) to a similar extent, whereas averaged word gender based on exclusively character words predicted trait words ($\beta$ `r description_model_char %>% filter(term == "token_gender_mean_char_scaled") %>% pull(print_pretty)`) but not activity words ($\beta$ `r activity_model_char %>% filter(term == "token_gender_mean_char_scaled") %>% pull(print_pretty)`; see SI for full model results). These results suggest that the averaged word gender measure described in Study 1b captures aspects of book gender bias, even after taking into account the broader context of the book text. Further, the difference in the genderedness of traits associated with by male vs. female primary characters is substantially larger than the effect observed in Study 1b. For example, male characters were more than twice as likely as female characters to be described as "playful" or "fun", whereas female characters were more than twice as likely as male characters to be described as "caring" or "quiet". 